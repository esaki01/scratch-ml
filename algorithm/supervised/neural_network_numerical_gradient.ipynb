{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワーク（Neural Network）\n",
    "## 数値勾配（Numerical Gradient）を用いた実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\koki5\\Dropbox\\Jupyter\\ScratchML')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from common.module.activation_function import sigmoid\n",
    "from common.module.activation_function import softmax\n",
    "from common.module.loss_function import cross_entropy_error\n",
    "from common.module.numeric import numerical_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの取得・確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train samples (60000, 784)\n",
      "y_train samples (60000, 10)\n",
      "X_test samples (10000, 784)\n",
      "y_test samples (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import pandas as pd\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784).astype('float32') / 255\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255\n",
    "y_train = np.array(pd.get_dummies(y_train))\n",
    "y_test = np.array(pd.get_dummies(y_test))\n",
    "\n",
    "print('X_train samples {}'.format(X_train.shape))\n",
    "print('y_train samples {}'.format(y_train.shape))\n",
    "print('X_test samples {}'.format(X_test.shape))\n",
    "print('y_test samples {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの構築・訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(object):\n",
    "    \"\"\"2層ニューラルネットワーク（隠れ層が1つ）.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init=0.01):\n",
    "        \"\"\"コンストラクタ.\n",
    "        \n",
    "        input_size: 入力層のニューロン数\n",
    "        hidden_size: 隠れ層のニューロン数\n",
    "        output_size: 出力層のニューロン数\n",
    "        weight_init: 重み初期化時のガウス分布のスケール\n",
    "        \"\"\"\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "        self._train_loss_list = []\n",
    "        self._train_acc_list = []\n",
    "        \n",
    "        \n",
    "    def fit(self, x, t, iters_num, batch_size, learning_rate):\n",
    "        \"\"\"学習する.\n",
    "        \n",
    "        x: 入力データ\n",
    "        t: ターゲット\n",
    "        iters_num: 訓練回数\n",
    "        batch_size: バッチサイズ\n",
    "        learning_rate: 学習率\n",
    "        \"\"\"\n",
    "        # 1エポックあたりの繰り返し数\n",
    "        iter_per_epoch = max(x.shape[0] / batch_size, 1)\n",
    "\n",
    "        for i in range(1, iters_num + 1):\n",
    "            # ミニバッチの取得\n",
    "            batch_mask = np.random.choice(x.shape[0], batch_size)\n",
    "            x_batch = x[batch_mask]\n",
    "            t_batch = t[batch_mask]\n",
    "    \n",
    "            # 勾配の計算\n",
    "            grad = self.gradient(x_batch, t_batch)\n",
    "    \n",
    "            # パラメータの更新\n",
    "            for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "                self.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "            # 学習過程の記録\n",
    "            loss = self.loss(x_batch, t_batch)\n",
    "            self._train_loss_list.append(loss)\n",
    "            print('\\r{}回目のError: {}'.format(i, loss), end='')\n",
    "    \n",
    "            # 1エポックごとに認識精度を計算\n",
    "            if i % iter_per_epoch == 0:\n",
    "                train_acc = self.accuracy(x, t)\n",
    "                self._train_acc_list.append(train_acc)\n",
    "                print()\n",
    "                print('{} epoch, train accuracy: {}'.format(int(i / iter_per_epoch), train_acc))\n",
    "                \n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"予測値を出力する.\n",
    "        \n",
    "        x: 入力データ\n",
    "        \"\"\"\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        \n",
    "        return softmax(a2)\n",
    "    \n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        \"\"\"エラー値を出力する.\n",
    "        \n",
    "        x: 入力データ\n",
    "        t: 教師データ\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        \"\"\"精度を求める.\n",
    "        \n",
    "        x: 入力データ\n",
    "        t: 教師データ\n",
    "        \"\"\"\n",
    "        y = np.argmax(self.predict(x), axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        return np.sum(y == t) / float(x.shape[0])\n",
    "    \n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"数値微分をする.\n",
    "        \n",
    "        x: 入力データ\n",
    "        t: 教師データ\n",
    "        \"\"\"\n",
    "        loss = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "network.fit(X_train, y_train, 3000, 100, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
